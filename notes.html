
from datetime import datetime, timedelta
import re
from robocorp.tasks import task
from RPA.Browser.Selenium import Selenium
from RPA.Browser.Selenium import By
from RPA.FileSystem import FileSystem
from RPA.Excel.Files import Files
# from task.news_scraper import NewsScraperBot


browser = Selenium()
filesystem = FileSystem()
excel = Files()

def is_within_date_range(date_str, months):
    try:
        article_date = datetime.strptime(date_str, '%d %B %Y')
    except ValueError:
        article_date = datetime.strptime(date_str, '%d %b %Y')  # Handle abbreviated months
    current_date = datetime.now()
    start_date = current_date - timedelta(days=30 * months)
    return start_date <= article_date <= current_date

def contains_money(text):
    patterns = [r'\$\d+(\.\d{1,2})?', r'\d+ dollars', r'\d+ USD']
    for pattern in patterns:
        if re.search(pattern, text):
            return True
    return False


@task
def main():
    browser = Selenium()
    browser.open_available_browser("https://www.aljazeera.com/")
    browser.click_button('css=button[data-testid="menu-trigger"]')
    browser.input_text('css=input[role="searchbox"]', 'technology')
    browser.press_keys('css=input[role="searchbox"]', 'ENTER')

    # Wait for the dropdown to be present
    browser.wait_until_element_is_visible('id=search-sort-option', timeout=10)
    
    # Select the sorting option by date
    browser.select_from_list_by_value('id=search-sort-option', 'date')
    try:
        browser.click_link("latest")
    except:
        print(f"Category latest not found. Proceeding without category filter.")

    articles = []

    browser.wait_until_page_contains_element("//div[@class='search-result__list']", timeout=30)

    # Get the search result list element
    # search_result_list = browser.find_elements("//div[@class='search-result__list']//article")
    search_result_list = browser.find_elements("//div[@class='search-result__list']//article")

    print(len(search_result_list))
     # Iterate through each article element to extract the required information
    for article in search_result_list:
        title = article.find_element(By.CSS_SELECTOR, '.gc__title').text
        date = article.find_element(By.CLASS_NAME, 'gc__meta').text
        description = article.find_element(By.CSS_SELECTOR, '.gc__excerpt').text
        picture_filename = article.find_element(By.CSS_SELECTOR, '.article-card__image').get_attribute('src')

        
        print(picture_filename)

    # print(search_result_list)
    # # Loop through articles on the search results page
    # for i in range(1, 21):  # Example limit, adjust as needed
    #     try:
    #         title = browser.get_text(f'xpath=(//h3)[{i}]')
    #         date = browser.get_text(f'xpath=(//time)[{i}]')
    #         description = browser.get_text(f'xpath=(//p)[{i}]')
            
    #         if is_within_date_range(date,2):
    #             article = {
    #                 'title': title,
    #                 'date': date,
    #                 'description': description,
    #                 'search_phrase_count': title.lower().count('war'.lower()) + description.lower().count('war'.lower()),
    #                 'contains_money': contains_money(title + ' ' + description)
    #             }
                
    #             # Download image
    #             image_url = browser.get_element_attribute(f'xpath=(//img)[{i}]', 'src')
    #             image_filename = f"news_image_{i}.jpg"
    #             browser.download(image_url, f"/output/{image_filename}")
    #             article['image_filename'] = image_filename
                
    #             articles.append(article)
    #     except:
    #         # Skip if any element is missing
    #         continue
    
    # # Sort articles by date to get the latest news
    # articles.sort(key=lambda x: datetime.strptime(x['date'], '%d %B %Y'), reverse=True)

    # # Prepare data for Excel
    # data = [["Title", "Date", "Description", "Image Filename", "Search Phrase Count", "Contains Money"]]
    # for article in articles:
    #     data.append([
    #         article['title'],
    #         article['date'],
    #         article['description'],
    #         article['image_filename'],
    #         article['search_phrase_count'],
    #         article['contains_money']
    #     ])

    # Save to Excel
    # print(data)
    # output_file = '/output/news_data.xlsx'
    # excel.create_workbook(output_file)
    # excel.append_rows_to_worksheet(data=data, name='News Data')
    # excel.save_workbook()
    # excel.close_workbook()


    
    # browser.input_text("id:react-aria4930188335-:r7:", "technology")
    # browser.press_keys("id:ybar-sbq", "ENTER")
    
    # bot = NewsScraperBot().browser_handler.open_browser('https://news.yahoo.com')
    # bot.run()

